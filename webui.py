#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import os
import sys
import threading
import time
import datetime
import shutil
import tempfile
from pathlib import Path
import asyncio
from concurrent.futures import ThreadPoolExecutor
from queue import Queue
import uuid

import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

# Windowsç³»ç»Ÿä¼˜åŒ–ï¼šè®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥ä»¥é¿å…è¿æ¥é‡ç½®é”™è¯¯
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)
sys.path.append(os.path.join(current_dir, "indextts"))

import argparse
parser = argparse.ArgumentParser(description="IndexTTS WebUI")
parser.add_argument("--verbose", action="store_true", default=False, help="Enable verbose mode")
parser.add_argument("--port", type=int, default=7866, help="Port to run the web UI on")
parser.add_argument("--host", type=str, default="0.0.0.0", help="Host to run the web UI on")
parser.add_argument("--model_dir", type=str, default="checkpoints", help="Model checkpoints directory")
cmd_args = parser.parse_args()

if not os.path.exists(cmd_args.model_dir):
    print(f"Model directory {cmd_args.model_dir} does not exist. Please download the model first.")
    sys.exit(1)

for file in [
    "bigvgan_generator.pth",
    "bpe.model",
    "gpt.pth",
    "config.yaml",
]:
    file_path = os.path.join(cmd_args.model_dir, file)
    if not os.path.exists(file_path):
        print(f"Required file {file_path} does not exist. Please download it.")
        sys.exit(1)

import gradio as gr
import pandas as pd

from indextts.infer import IndexTTS
from tools.i18n.i18n import I18nAuto

i18n = I18nAuto(language="zh_CN")
MODE = 'local'
tts = IndexTTS(model_dir=cmd_args.model_dir, cfg_path=os.path.join(cmd_args.model_dir, "config.yaml"),)

# åå°ä»»åŠ¡ç®¡ç†
task_executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="TTS_Task")
task_queue = Queue()
task_status = {}  # ä»»åŠ¡çŠ¶æ€å­—å…¸: {task_id: {"status": str, "progress": str, "result": str, "error": str}}
task_lock = threading.Lock()

os.makedirs("outputs", exist_ok=True)
os.makedirs("prompts",exist_ok=True)
os.makedirs("samples",exist_ok=True)

# Helper functions for file processing
def read_txt_file(file_path):
    """Read text from txt file"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except:
        try:
            with open(file_path, 'r', encoding='gbk') as f:
                return f.read()
        except:
            return ""

def read_epub_file(file_path):
    """Read text from epub file"""
    try:
        import ebooklib
        from ebooklib import epub
        from bs4 import BeautifulSoup
        import re
        
        book = epub.read_epub(file_path)
        text_content = []
        chapters = []
        
        for item in book.get_items():
            if item.get_type() == ebooklib.ITEM_DOCUMENT:
                soup = BeautifulSoup(item.get_content(), 'html.parser')
                content = soup.get_text()
                
                # Try to extract chapter title from the content or filename
                chapter_title = None
                
                # Look for chapter titles in h1, h2, h3 tags
                for tag in soup.find_all(['h1', 'h2', 'h3']):
                    title_text = tag.get_text().strip()
                    if title_text and (re.search(r'ç¬¬.{1,10}ç« |chapter|Chapter|CHAPTER', title_text) or len(title_text) < 100):
                        chapter_title = title_text
                        break
                
                # If no title found, use filename or create generic title
                if not chapter_title:
                    filename = getattr(item, 'file_name', '')
                    if filename:
                        chapter_title = filename.replace('.xhtml', '').replace('.html', '')
                    else:
                        chapter_title = f"ç« èŠ‚ {len(chapters) + 1}"
                
                # Record chapter start position
                current_length = len('\n'.join(text_content))
                if content.strip():  # Only add if content is not empty
                    chapters.append({
                        'title': chapter_title,
                        'start_pos': current_length,
                        'content': content
                    })
                    text_content.append(content)
        
        full_text = '\n'.join(text_content)
        return full_text, chapters
        
    except ImportError:
        return "éœ€è¦å®‰è£… ebooklib å’Œ beautifulsoup4 æ‰èƒ½è¯»å– EPUB æ–‡ä»¶", []
    except:
        return "è¯»å– EPUB æ–‡ä»¶å¤±è´¥", []

def convert_audio_format(input_path, output_path, format_type="mp3", bitrate="64k", chapters=None):
    """Convert audio to different formats with optional chapter support"""
    try:
        import subprocess
        import tempfile
        import os
        
        print(f">> å¼€å§‹éŸ³é¢‘æ ¼å¼è½¬æ¢:")
        print(f"   è¾“å…¥æ–‡ä»¶: {input_path}")
        print(f"   è¾“å‡ºæ–‡ä»¶: {output_path}")
        print(f"   æ ¼å¼: {format_type}")
        print(f"   æ¯”ç‰¹ç‡: {bitrate}")
        print(f"   ç« èŠ‚æ•°: {len(chapters) if chapters else 0}")
        
        # Check if input file exists
        if not os.path.exists(input_path):
            print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
            return False
        
        # Check if ffmpeg is available
        try:
            subprocess.run(["ffmpeg", "-version"], capture_output=True, check=True, encoding='utf-8', errors='ignore')
        except (subprocess.CalledProcessError, FileNotFoundError):
            print("âŒ é”™è¯¯: ffmpeg æœªå®‰è£…æˆ–ä¸åœ¨PATHä¸­")
            return False
        
        chapter_file_path = None
        
        if format_type == "mp3":
            cmd = ["ffmpeg", "-i", input_path, "-b:a", bitrate, "-y", output_path]
        elif format_type == "m4b":
            # Start with basic input
            cmd = ["ffmpeg", "-i", input_path]
            
            # Add chapters if provided
            if chapters and len(chapters) > 1:
                print(f">> åˆ›å»ºç« èŠ‚å…ƒæ•°æ®æ–‡ä»¶ï¼Œå…± {len(chapters)} ä¸ªç« èŠ‚")
                # Create a temporary chapter file
                with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8', newline='') as chapter_file:
                    chapter_file.write(";FFMETADATA1\n")
                    
                    # Calculate approximate chapter timings
                    # This is a rough estimation based on text length
                    total_chars = sum(len(ch.get('content', '')) for ch in chapters)
                    # Estimate total duration: ~150 characters per minute
                    total_duration = (total_chars / 150) * 60 * 1000  # milliseconds
                    current_time = 0
                    
                    print(f"   æ€»å­—ç¬¦æ•°: {total_chars}")
                    print(f"   é¢„è®¡æ€»æ—¶é•¿: {total_duration/1000:.1f}ç§’")
                    
                    for i, chapter in enumerate(chapters):
                        chapter_chars = len(chapter.get('content', ''))
                        # Estimate: ~150 characters per minute (rough speaking rate)
                        chapter_duration = (chapter_chars / 150) * 60 * 1000  # milliseconds
                        
                        start_time = int(current_time)
                        chapter_file.write(f"\n[CHAPTER]\n")
                        chapter_file.write(f"TIMEBASE=1/1000\n")
                        chapter_file.write(f"START={start_time}\n")
                        
                        # End time for current chapter
                        if i < len(chapters) - 1:
                            end_time = int(current_time + chapter_duration)
                        else:
                            # Last chapter goes to end of estimated total duration
                            end_time = int(total_duration)
                        
                        chapter_file.write(f"END={end_time}\n")
                        
                        # Clean chapter title for metadata
                        title = chapter.get('title', f'Chapter {i+1}')
                        title = title.replace('=', '\\=').replace(';', '\\;').replace('#', '\\#')
                        chapter_file.write(f"title={title}\n")
                        
                        print(f"   ç« èŠ‚ {i+1}: {title} ({start_time}ms - {end_time}ms)")
                        
                        current_time += chapter_duration
                    
                    chapter_file_path = chapter_file.name
                    print(f"   ç« èŠ‚æ–‡ä»¶: {chapter_file_path}")
                
                # Add metadata file to ffmpeg command
                cmd.extend(["-i", chapter_file_path, "-map_metadata", "1"])
            
            # Add output options
            cmd.extend(["-c:a", "aac", "-b:a", bitrate, "-f", "ipod", "-y", output_path])
        else:
            print(f"âŒ é”™è¯¯: ä¸æ”¯æŒçš„æ ¼å¼: {format_type}")
            return False
        
        print(f">> æ‰§è¡Œ ffmpeg å‘½ä»¤: {' '.join(cmd)}")
        
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore')
        
        print(f">> ffmpeg è¿”å›ç : {result.returncode}")
        if result.stdout:
            print(f">> ffmpeg è¾“å‡º: {result.stdout}")
        if result.stderr:
            print(f">> ffmpeg é”™è¯¯: {result.stderr}")
        
        # Clean up temporary chapter file
        if chapter_file_path:
            try:
                os.unlink(chapter_file_path)
                print(f">> å·²åˆ é™¤ä¸´æ—¶ç« èŠ‚æ–‡ä»¶: {chapter_file_path}")
            except Exception as e:
                print(f">> åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
        
        success = result.returncode == 0
        if success:
            if os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / 1024 / 1024  # MB
                print(f"âœ… æ ¼å¼è½¬æ¢æˆåŠŸ: {output_path} ({file_size:.2f} MB)")
            else:
                print(f"âŒ è½¬æ¢å¤±è´¥: è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
                success = False
        else:
            print(f"âŒ ffmpeg è½¬æ¢å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
        
        return success
        
    except Exception as e:
        print(f"âŒ æ ¼å¼è½¬æ¢å¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def get_sample_files():
    """Get list of sample audio files"""
    samples_dir = "samples"
    if not os.path.exists(samples_dir):
        os.makedirs(samples_dir)
        return []
    
    # Only include standard audio formats that can be loaded by torchaudio
    supported_formats = ['.wav', '.mp3']
    files = []
    
    for file in os.listdir(samples_dir):
        if any(file.lower().endswith(ext) for ext in supported_formats):
            files.append(file)
    
    return sorted(files)

def get_speaker_name_from_path(audio_path):
    """Extract speaker name from audio file path"""
    if audio_path:
        # Handle different formats that Gradio Audio might return
        if isinstance(audio_path, tuple):
            # If it's a tuple, take the first element (usually the file path)
            audio_path = audio_path[0] if audio_path else None
        
        if audio_path and isinstance(audio_path, str):
            filename = os.path.basename(audio_path)
            name = os.path.splitext(filename)[0]
            return name
    return "unknown"

# åå°ä»»åŠ¡å¤„ç†ç³»ç»Ÿ
def update_task_status(task_id, status=None, progress=None, result=None, error=None):
    """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
    with task_lock:
        if task_id not in task_status:
            task_status[task_id] = {"status": "unknown", "progress": "", "result": "", "error": ""}
        
        if status is not None:
            task_status[task_id]["status"] = status
        if progress is not None:
            task_status[task_id]["progress"] = progress
        if result is not None:
            task_status[task_id]["result"] = result
        if error is not None:
            task_status[task_id]["error"] = error

def get_task_status(task_id):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    with task_lock:
        return task_status.get(task_id, {"status": "not_found", "progress": "", "result": "", "error": "ä»»åŠ¡ä¸å­˜åœ¨"})

def background_audio_generation(task_id, prompt_path, text_to_process, infer_mode, 
                               max_text_tokens_per_sentence, sentences_bucket_max_size,
                               audio_format, output_path, temp_wav_path, chapters, kwargs):
    """åå°éŸ³é¢‘ç”Ÿæˆå‡½æ•°"""
    try:
        print(f"=== åå°ä»»åŠ¡ {task_id} å¼€å§‹ ===")
        update_task_status(task_id, status="ğŸš€ åˆå§‹åŒ–", progress="æ­£åœ¨å‡†å¤‡ç”Ÿæˆå‚æ•°...")
        
        # åˆ›å»ºä»»åŠ¡ä¸“ç”¨çš„è¿›åº¦å›è°ƒ
        class TaskProgress:
            def __init__(self, task_id):
                self.task_id = task_id
                self.last_update = time.time()
                self.last_system_update = time.time()
                self.start_time = time.time()
            
            def format_time(self, seconds):
                """æ ¼å¼åŒ–æ—¶é—´ä¸ºäººç±»å¯è¯»æ ¼å¼"""
                if seconds < 60:
                    return f"{seconds:.1f}ç§’"
                elif seconds < 3600:
                    minutes = seconds / 60
                    return f"{minutes:.1f}åˆ†é’Ÿ"
                else:
                    hours = seconds / 3600
                    return f"{hours:.1f}å°æ—¶"
            
            def __call__(self, progress=None, desc=None):
                current_time = time.time()
                # é™åˆ¶æ›´æ–°é¢‘ç‡ï¼Œé¿å…è¿‡äºé¢‘ç¹çš„çŠ¶æ€æ›´æ–°
                if current_time - self.last_update > 1.0:  # æ¯ç§’æœ€å¤šæ›´æ–°ä¸€æ¬¡
                    progress_text = ""
                    if desc:
                        progress_text = f"ğŸµ {desc}"
                        
                        # æ·»åŠ æ—¶é—´ä¿¡æ¯
                        elapsed = current_time - self.start_time
                        elapsed_formatted = self.format_time(elapsed)
                        progress_text += f"\nâ±ï¸ å·²ç”¨æ—¶: {elapsed_formatted}"
                        
                    elif progress is not None:
                        elapsed = current_time - self.start_time
                        elapsed_formatted = self.format_time(elapsed)
                        progress_text = f"ğŸµ è¿›åº¦: {progress:.1f}%\nâ±ï¸ å·²ç”¨æ—¶: {elapsed_formatted}"
                    
                    # æ¯5ç§’æ·»åŠ ä¸€æ¬¡ç³»ç»Ÿä¿¡æ¯
                    if current_time - self.last_system_update > 5.0:
                        try:
                            system_info = get_system_status()
                            progress_text += f"\n\nğŸ“Š ç³»ç»ŸçŠ¶æ€:\n{system_info}"
                            self.last_system_update = current_time
                        except:
                            pass  # å¿½ç•¥ç³»ç»Ÿä¿¡æ¯è·å–é”™è¯¯
                    
                    update_task_status(self.task_id, progress=progress_text)
                    self.last_update = current_time
        
        # è®¾ç½®ä»»åŠ¡ä¸“ç”¨çš„è¿›åº¦å›è°ƒ
        task_progress = TaskProgress(task_id)
        tts.gr_progress = task_progress
        
        # å¼€å§‹éŸ³é¢‘ç”Ÿæˆ
        update_task_status(task_id, status="ğŸµ ç”ŸæˆéŸ³é¢‘", progress="æ­£åœ¨ç”ŸæˆéŸ³é¢‘ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        print(f"[Task {task_id}] å¼€å§‹éŸ³é¢‘ç”Ÿæˆ...")
        
        start_time = time.time()
        if infer_mode == "æ™®é€šæ¨ç†":
            wav_output = tts.infer(prompt_path, text_to_process, temp_wav_path, verbose=cmd_args.verbose,
                               max_text_tokens_per_sentence=int(max_text_tokens_per_sentence),
                               **kwargs)
        else:
            # æ‰¹æ¬¡æ¨ç†
            wav_output = tts.infer_fast(prompt_path, text_to_process, temp_wav_path, verbose=cmd_args.verbose,
                max_text_tokens_per_sentence=int(max_text_tokens_per_sentence),
                sentences_bucket_max_size=(sentences_bucket_max_size),
                **kwargs)
        
        generation_time = time.time() - start_time
        print(f"[Task {task_id}] éŸ³é¢‘ç”Ÿæˆå®Œæˆ: {wav_output}")
        print(f"[Task {task_id}] ç”Ÿæˆè€—æ—¶: {generation_time:.2f} ç§’")
        
        # æ ¼å¼è½¬æ¢
        final_output = wav_output
        if audio_format != "WAV":
            update_task_status(task_id, status="ğŸ”„ æ ¼å¼è½¬æ¢", progress=f"æ­£åœ¨è½¬æ¢åˆ° {audio_format} æ ¼å¼...")
            print(f"[Task {task_id}] è½¬æ¢éŸ³é¢‘æ ¼å¼åˆ° {audio_format}...")
            
            if audio_format == "MP3":
                if convert_audio_format(wav_output, output_path, "mp3", "64k"):
                    final_output = output_path
                    # Remove temp wav file
                    if os.path.exists(temp_wav_path) and temp_wav_path != output_path:
                        os.remove(temp_wav_path)
            elif audio_format == "M4B":
                conversion_success = convert_audio_format(wav_output, output_path, "m4b", "64k", chapters)
                if conversion_success:
                    final_output = output_path
                    print(f"[Task {task_id}] âœ… M4Bè½¬æ¢æˆåŠŸ: {output_path}")
                    # Remove temp wav file
                    if os.path.exists(temp_wav_path) and temp_wav_path != output_path:
                        os.remove(temp_wav_path)
                        print(f"[Task {task_id}] >> å·²åˆ é™¤ä¸´æ—¶WAVæ–‡ä»¶: {temp_wav_path}")
                else:
                    print(f"[Task {task_id}] âŒ M4Bè½¬æ¢å¤±è´¥ï¼Œä¿ç•™åŸWAVæ–‡ä»¶: {wav_output}")
        
        # ä»»åŠ¡å®Œæˆ
        file_size = os.path.getsize(final_output) / 1024 / 1024  # MB
        success_info = f"âœ… ç”Ÿæˆå®Œæˆï¼\nâ±ï¸ æ€»è€—æ—¶: {generation_time:.2f} ç§’\nğŸ“ æ–‡ä»¶: {os.path.basename(final_output)}\nğŸ“ å¤§å°: {file_size:.2f} MB"
        
        update_task_status(task_id, 
                         status="âœ… å®Œæˆ", 
                         progress=success_info,
                         result=final_output)
        
        print(f"=== åå°ä»»åŠ¡ {task_id} å®Œæˆ ===")
        return final_output
        
    except Exception as e:
        error_msg = f"âŒ ç”ŸæˆéŸ³é¢‘æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        print(f"[Task {task_id}] ERROR: {error_msg}")
        import traceback
        error_traceback = traceback.format_exc()
        print(error_traceback)
        
        detailed_error = f"é”™è¯¯ç±»å‹: {type(e).__name__}\né”™è¯¯ä¿¡æ¯: {str(e)}\n\nè¯¦ç»†å †æ ˆ:\n{error_traceback}"
        update_task_status(task_id, 
                         status="âŒ å¤±è´¥", 
                         error=detailed_error)
        return None

def submit_background_task(prompt_path, text_to_process, infer_mode, 
                          max_text_tokens_per_sentence, sentences_bucket_max_size,
                          audio_format, output_path, temp_wav_path, chapters, kwargs):
    """æäº¤åå°ä»»åŠ¡"""
    task_id = str(uuid.uuid4())[:8]  # ç”ŸæˆçŸ­ä»»åŠ¡ID
    
    # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
    update_task_status(task_id, status="â³ æ’é˜Ÿä¸­", progress="ä»»åŠ¡å·²æäº¤ï¼Œç­‰å¾…å¤„ç†...")
    
    # æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
    future = task_executor.submit(
        background_audio_generation,
        task_id, prompt_path, text_to_process, infer_mode,
        max_text_tokens_per_sentence, sentences_bucket_max_size,
        audio_format, output_path, temp_wav_path, chapters, kwargs
    )
    
    print(f"å·²æäº¤åå°ä»»åŠ¡: {task_id}")
    return task_id

def get_all_tasks():
    """è·å–æ‰€æœ‰ä»»åŠ¡çŠ¶æ€"""
    with task_lock:
        return dict(task_status)

def clear_completed_tasks():
    """æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡"""
    with task_lock:
        completed_tasks = []
        for task_id, status in task_status.items():
            if status["status"] in ["âœ… å®Œæˆ", "âŒ å¤±è´¥"]:
                completed_tasks.append(task_id)
        
        for task_id in completed_tasks:
            del task_status[task_id]
        
        return len(completed_tasks)

with open("tests/cases.jsonl", "r", encoding="utf-8") as f:
    example_cases = []
    for line in f:
        line = line.strip()
        if not line:
            continue
        example = json.loads(line)
        example_cases.append([os.path.join("tests", example.get("prompt_audio", "sample_prompt.wav")),
                              example.get("text"), ["æ™®é€šæ¨ç†", "æ‰¹æ¬¡æ¨ç†"][example.get("infer_mode", 0)]])

def gen_single(prompt, text, infer_mode, max_text_tokens_per_sentence=120, sentences_bucket_max_size=6,
                auto_save=True, audio_format="MP3", uploaded_file_name="", selected_sample="", full_text="", chapters=None, 
                background_mode=True, *args, progress=gr.Progress()):
    
    def update_status(status, detailed_progress="", system_status="", error_msg="", show_progress=False, show_system=False, show_error=False):
        """æ›´æ–°çŠ¶æ€æ˜¾ç¤º"""
        return (
            gr.update(value=status),
            gr.update(value=detailed_progress, visible=show_progress),
            gr.update(value=system_status, visible=show_system),
            gr.update(value=error_msg, visible=show_error)
        )
    try:
        print(f"=== å¼€å§‹éŸ³é¢‘ç”Ÿæˆ ===")
        print(f"è¾“å…¥å‚æ•°: prompt={prompt}, text={text[:50] if text else None}{'...' if text and len(text) > 50 else ''}")
        print(f"æ¨ç†æ¨¡å¼: {infer_mode}, æ ¼å¼: {audio_format}, è‡ªåŠ¨ä¿å­˜: {auto_save}")
        
        # åˆå§‹çŠ¶æ€æ›´æ–°
        initial_system_info = get_system_status()
        status_updates = update_status("ğŸš€ å¼€å§‹éŸ³é¢‘ç”Ÿæˆ...", "æ­£åœ¨éªŒè¯è¾“å…¥å‚æ•°...", initial_system_info, show_progress=True, show_system=True)
        
        # Handle audio input - prioritize selected sample over audio component
        prompt_path = None
        
        # First, try to use selected sample file
        if selected_sample and selected_sample != "æ— å¯ç”¨æ–‡ä»¶":
            prompt_path = os.path.join("samples", selected_sample)
            print(f"ä½¿ç”¨é€‰ä¸­çš„æ ·æœ¬æ–‡ä»¶: {selected_sample}")
        
        # If no sample selected, try to handle direct audio upload (if any)
        elif prompt is not None:
            if isinstance(prompt, tuple) and len(prompt) == 2:
                # Audio data format: (sample_rate, audio_array)
                # For now, we need to save this to a temporary file
                import numpy as np
                import soundfile as sf
                
                sample_rate, audio_data = prompt
                print(f"æ¥æ”¶åˆ°éŸ³é¢‘æ•°æ®: é‡‡æ ·ç‡={sample_rate}, æ•°æ®å½¢çŠ¶={audio_data.shape}")
                
                # Create temporary wav file
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                    # Convert int16 to float32 if needed
                    if audio_data.dtype == np.int16:
                        audio_data = audio_data.astype(np.float32) / 32768.0
                    sf.write(tmp_file.name, audio_data, sample_rate)
                    prompt_path = tmp_file.name
                    print(f"å·²ä¿å­˜ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶: {prompt_path}")
            elif isinstance(prompt, str):
                prompt_path = prompt
        
        print(f"æœ€ç»ˆå‚è€ƒéŸ³é¢‘è·¯å¾„: {prompt_path}")
        
        # Validate inputs
        if not prompt_path:
            error_msg = "âŒ é”™è¯¯ï¼šæœªé€‰æ‹©å‚è€ƒéŸ³é¢‘æ–‡ä»¶"
            print(error_msg)
            status_updates = update_status("âŒ ç”Ÿæˆå¤±è´¥", "", "", error_msg, show_error=True)
            return gr.update(value=None, visible=True), *status_updates
        
        if not os.path.exists(prompt_path):
            error_msg = f"âŒ é”™è¯¯ï¼šå‚è€ƒéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {prompt_path}"
            print(error_msg)
            status_updates = update_status("âŒ ç”Ÿæˆå¤±è´¥", "", "", error_msg, show_error=True)
            return gr.update(value=None, visible=True), *status_updates
        
        # Check if TTS model is loaded
        if not hasattr(tts, 'infer') or not hasattr(tts, 'tokenizer'):
            error_msg = "âŒ é”™è¯¯ï¼šTTSæ¨¡å‹æœªæ­£ç¡®åŠ è½½"
            print(error_msg)
            status_updates = update_status("âŒ ç”Ÿæˆå¤±è´¥", "", "", error_msg, show_error=True)
            return gr.update(value=None, visible=True), *status_updates
    

    
        # Validate text input
        text_to_process = full_text if full_text.strip() else text
        if not text_to_process or not text_to_process.strip():
            error_msg = "âŒ é”™è¯¯ï¼šæœªè¾“å…¥æ–‡æœ¬å†…å®¹"
            print(error_msg)
            status_updates = update_status("âŒ ç”Ÿæˆå¤±è´¥", "", "", error_msg, show_error=True)
            return gr.update(value=None, visible=True), *status_updates
        
        print(f"å¾…å¤„ç†æ–‡æœ¬é•¿åº¦: {len(text_to_process)}")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åå°å¤„ç†
        text_length = len(text_to_process)
        estimated_time = text_length / 100  # ç²—ç•¥ä¼°ç®—ï¼šæ¯100å­—ç¬¦çº¦1ç§’
        
        # å¦‚æœæ–‡æœ¬å¾ˆé•¿ï¼ˆè¶…è¿‡5000å­—ç¬¦ï¼‰æˆ–é¢„è®¡æ—¶é—´è¶…è¿‡60ç§’ï¼Œå¼ºåˆ¶ä½¿ç”¨åå°æ¨¡å¼
        if background_mode and (text_length > 5000 or estimated_time > 60):
            print(f"æ–‡æœ¬è¾ƒé•¿({text_length}å­—ç¬¦)ï¼Œé¢„è®¡è€—æ—¶{estimated_time:.1f}ç§’ï¼Œåˆ‡æ¢åˆ°åå°å¤„ç†æ¨¡å¼")
            
            # å‡†å¤‡åå°ä»»åŠ¡å‚æ•°
            # æ›´æ–°çŠ¶æ€ï¼šå‡†å¤‡ç”Ÿæˆ
            detailed_info = f"ğŸ“ æ–‡æœ¬é•¿åº¦: {len(text_to_process)} å­—ç¬¦\nğŸµ å‚è€ƒéŸ³é¢‘: {os.path.basename(prompt_path)}\nâš™ï¸ æ¨ç†æ¨¡å¼: {infer_mode}\nğŸ“ è¾“å‡ºæ ¼å¼: {audio_format}\nâ° é¢„è®¡è€—æ—¶: {estimated_time:.1f}ç§’"
            current_system_info = get_system_status()
            status_updates = update_status("ğŸ“‹ å‡†å¤‡åå°ä»»åŠ¡...", detailed_info, current_system_info, show_progress=True, show_system=True)
            
            # Generate date and speaker name
            date = datetime.datetime.now().strftime("%Y%m%d")
            speaker_name = get_speaker_name_from_path(prompt_path)
            
            # Create output filename based on source
            if uploaded_file_name:
                # If text comes from uploaded file: æ–‡ä»¶å_æ—¥æœŸ_éŸ³è‰²
                base_name = os.path.splitext(uploaded_file_name)[0]
                filename = f"{base_name}_{date}_{speaker_name}"
            else:
                # Regular text input: æ—¥æœŸ_éŸ³è‰²
                filename = f"{date}_{speaker_name}"
            
            # Set output path with proper extension
            if audio_format == "MP3":
                output_path = os.path.join("outputs", f"{filename}.mp3")
                temp_wav_path = os.path.join("outputs", f"temp_{date}_{int(time.time())}.wav")
            elif audio_format == "M4B":
                output_path = os.path.join("outputs", f"{filename}.m4b")
                temp_wav_path = os.path.join("outputs", f"temp_{date}_{int(time.time())}.wav")
            else:  # WAV
                output_path = os.path.join("outputs", f"{filename}.wav")
                temp_wav_path = output_path
            
            # Ensure outputs directory exists
            os.makedirs("outputs", exist_ok=True)
            
            # å‡†å¤‡ç”Ÿæˆå‚æ•°
            do_sample, top_p, top_k, temperature, \
                length_penalty, num_beams, repetition_penalty, max_mel_tokens = args
            kwargs = {
                "do_sample": bool(do_sample),
                "top_p": float(top_p),
                "top_k": int(top_k) if int(top_k) > 0 else None,
                "temperature": float(temperature),
                "length_penalty": float(length_penalty),
                "num_beams": num_beams,
                "repetition_penalty": float(repetition_penalty),
                "max_mel_tokens": int(max_mel_tokens),
            }
            
            # æäº¤åå°ä»»åŠ¡
            task_id = submit_background_task(
                prompt_path, text_to_process, infer_mode,
                max_text_tokens_per_sentence, sentences_bucket_max_size,
                audio_format, output_path, temp_wav_path, chapters, kwargs
            )
            
            # è¿”å›ä»»åŠ¡ä¿¡æ¯
            task_info = f"ğŸš€ åå°ä»»åŠ¡å·²æäº¤\nğŸ“‹ ä»»åŠ¡ID: {task_id}\nğŸ“ æ–‡æœ¬é•¿åº¦: {text_length} å­—ç¬¦\nâ° é¢„è®¡è€—æ—¶: {estimated_time:.1f}ç§’\n\nğŸ’¡ æ‚¨å¯ä»¥å…³é—­æµè§ˆå™¨ï¼Œä»»åŠ¡å°†ç»§ç»­åœ¨åå°è¿è¡Œã€‚\nğŸ“ å®Œæˆåæ–‡ä»¶å°†ä¿å­˜åˆ°: {os.path.basename(output_path)}\n\nğŸ”„ è¯·å‰å¾€ã€ä»»åŠ¡ç®¡ç†ã€‘é¡µé¢æŸ¥çœ‹è¿›åº¦ã€‚"
            final_system_info = get_system_status()
            status_updates = update_status("ğŸš€ åå°ä»»åŠ¡å·²æäº¤", task_info, final_system_info, show_progress=True, show_system=True)
            
            # Clean up temporary prompt file if it was created
            if prompt_path and tempfile.gettempdir() in prompt_path:
                try:
                    os.remove(prompt_path)
                    print(f"å·²æ¸…ç†ä¸´æ—¶å‚è€ƒéŸ³é¢‘æ–‡ä»¶: {prompt_path}")
                except:
                    pass  # Ignore cleanup errors
            
            return gr.update(value=None, visible=True), *status_updates
        
        # ç»§ç»­å‰å°å¤„ç†ï¼ˆçŸ­æ–‡æœ¬ï¼‰
        # æ›´æ–°çŠ¶æ€ï¼šå‡†å¤‡ç”Ÿæˆ
        detailed_info = f"ğŸ“ æ–‡æœ¬é•¿åº¦: {len(text_to_process)} å­—ç¬¦\nğŸµ å‚è€ƒéŸ³é¢‘: {os.path.basename(prompt_path)}\nâš™ï¸ æ¨ç†æ¨¡å¼: {infer_mode}\nğŸ“ è¾“å‡ºæ ¼å¼: {audio_format}"
        prep_system_info = get_system_status()
        status_updates = update_status("ğŸ“‹ å‡†å¤‡ç”Ÿæˆå‚æ•°...", detailed_info, prep_system_info, show_progress=True, show_system=True)
        
        # Generate date and speaker name
        date = datetime.datetime.now().strftime("%Y%m%d")
        speaker_name = get_speaker_name_from_path(prompt_path)
        
        # Create output filename based on source
        if uploaded_file_name:
            # If text comes from uploaded file: æ–‡ä»¶å_æ—¥æœŸ_éŸ³è‰²
            base_name = os.path.splitext(uploaded_file_name)[0]
            filename = f"{base_name}_{date}_{speaker_name}"
        else:
            # Regular text input: æ—¥æœŸ_éŸ³è‰²
            filename = f"{date}_{speaker_name}"
        
        print(f"è¾“å‡ºæ–‡ä»¶å: {filename}")
        
        # Set output path with proper extension
        if audio_format == "MP3":
            output_path = os.path.join("outputs", f"{filename}.mp3")
            temp_wav_path = os.path.join("outputs", f"temp_{date}_{int(time.time())}.wav")  # Temp file without dot prefix
        elif audio_format == "M4B":
            output_path = os.path.join("outputs", f"{filename}.m4b")
            temp_wav_path = os.path.join("outputs", f"temp_{date}_{int(time.time())}.wav")  # Temp file without dot prefix
        else:  # WAV
            output_path = os.path.join("outputs", f"{filename}.wav")
            temp_wav_path = output_path
        
        print(f"è¾“å‡ºè·¯å¾„: {output_path}")
        
        # Ensure outputs directory exists
        os.makedirs("outputs", exist_ok=True)
        
        # åˆ›å»ºå¢å¼ºçš„è¿›åº¦å›è°ƒ
        class EnhancedProgress:
            def __init__(self, original_progress, update_func):
                self.original_progress = original_progress
                self.update_func = update_func
                self.last_system_update = time.time()
                self.start_time = time.time()
            
            def format_time(self, seconds):
                """æ ¼å¼åŒ–æ—¶é—´ä¸ºäººç±»å¯è¯»æ ¼å¼"""
                if seconds < 60:
                    return f"{seconds:.1f}ç§’"
                elif seconds < 3600:
                    minutes = seconds / 60
                    return f"{minutes:.1f}åˆ†é’Ÿ"
                else:
                    hours = seconds / 3600
                    return f"{hours:.1f}å°æ—¶"
            
            def __call__(self, value, desc=None):
                current_time = time.time()
                # æ¯2ç§’æ›´æ–°ä¸€æ¬¡ç³»ç»Ÿä¿¡æ¯ï¼Œé¿å…è¿‡äºé¢‘ç¹
                if current_time - self.last_system_update > 2.0:
                    try:
                        system_info = get_system_status()
                        # æ·»åŠ æ—¶é—´ä¿¡æ¯åˆ°æè¿°ä¸­
                        elapsed = current_time - self.start_time
                        elapsed_formatted = self.format_time(elapsed)
                        
                        enhanced_desc = desc or "æ­£åœ¨ç”ŸæˆéŸ³é¢‘..."
                        enhanced_desc += f"\nâ±ï¸ å·²ç”¨æ—¶: {elapsed_formatted}"
                        
                        self.update_func("ğŸµ æ­£åœ¨ç”ŸæˆéŸ³é¢‘...", enhanced_desc, system_info, show_progress=True, show_system=True)
                        self.last_system_update = current_time
                    except:
                        pass  # å¿½ç•¥ç³»ç»Ÿä¿¡æ¯æ›´æ–°é”™è¯¯
                
                # è°ƒç”¨åŸå§‹è¿›åº¦å›è°ƒ
                if self.original_progress:
                    self.original_progress(value, desc=desc)
        
        # è®¾ç½®å¢å¼ºçš„è¿›åº¦å›è°ƒ
        enhanced_progress = EnhancedProgress(progress, update_status)
        tts.gr_progress = enhanced_progress
        do_sample, top_p, top_k, temperature, \
            length_penalty, num_beams, repetition_penalty, max_mel_tokens = args
        kwargs = {
            "do_sample": bool(do_sample),
            "top_p": float(top_p),
            "top_k": int(top_k) if int(top_k) > 0 else None,
            "temperature": float(temperature),
            "length_penalty": float(length_penalty),
            "num_beams": num_beams,
            "repetition_penalty": float(repetition_penalty),
            "max_mel_tokens": int(max_mel_tokens),
        }
        
        print(f"ç”Ÿæˆå‚æ•°: {kwargs}")
        
        # æ›´æ–°çŠ¶æ€ï¼šå¼€å§‹ç”Ÿæˆ
        generation_info = f"ğŸ¯ æ¨ç†æ¨¡å¼: {infer_mode}\nğŸ“Š æœ€å¤§Tokenæ•°: {max_text_tokens_per_sentence}"
        if infer_mode == "æ‰¹æ¬¡æ¨ç†":
            generation_info += f"\nğŸ—‚ï¸ åˆ†æ¡¶å¤§å°: {sentences_bucket_max_size}"
        generation_info += f"\nğŸ›ï¸ æ¸©åº¦: {kwargs.get('temperature', 1.0)}\nğŸ² é‡‡æ ·: {'å¼€å¯' if kwargs.get('do_sample', True) else 'å…³é—­'}"
        gen_system_info = get_system_status()
        status_updates = update_status("ğŸµ æ­£åœ¨ç”ŸæˆéŸ³é¢‘...", generation_info, gen_system_info, show_progress=True, show_system=True)
        
        # Generate audio
        print(f"å¼€å§‹éŸ³é¢‘ç”Ÿæˆ...")
        start_time = time.time()
        if infer_mode == "æ™®é€šæ¨ç†":
            wav_output = tts.infer(prompt_path, text_to_process, temp_wav_path, verbose=cmd_args.verbose,
                               max_text_tokens_per_sentence=int(max_text_tokens_per_sentence),
                               **kwargs)
        else:
            # æ‰¹æ¬¡æ¨ç†
            wav_output = tts.infer_fast(prompt_path, text_to_process, temp_wav_path, verbose=cmd_args.verbose,
                max_text_tokens_per_sentence=int(max_text_tokens_per_sentence),
                sentences_bucket_max_size=(sentences_bucket_max_size),
                **kwargs)
        
        generation_time = time.time() - start_time
        print(f"éŸ³é¢‘ç”Ÿæˆå®Œæˆ: {wav_output}")
        print(f"ç”Ÿæˆè€—æ—¶: {generation_time:.2f} ç§’")
        
        # Convert audio format if needed
        final_output = wav_output
        if auto_save and audio_format != "WAV":
            print(f"è½¬æ¢éŸ³é¢‘æ ¼å¼åˆ° {audio_format}...")
            # æ›´æ–°çŠ¶æ€ï¼šæ ¼å¼è½¬æ¢
            conversion_info = f"ğŸ”„ æ­£åœ¨è½¬æ¢åˆ° {audio_format} æ ¼å¼...\nğŸ“ è¾“å‡ºè·¯å¾„: {output_path}"
            if audio_format == "M4B" and chapters:
                conversion_info += f"\nğŸ“– æ·»åŠ ç« èŠ‚ä¹¦ç­¾: {len(chapters)} ä¸ªç« èŠ‚"
            conv_system_info = get_system_status()
            status_updates = update_status("ğŸ”„ è½¬æ¢éŸ³é¢‘æ ¼å¼...", conversion_info, conv_system_info, show_progress=True, show_system=True)
            
            if audio_format == "MP3":
                if convert_audio_format(wav_output, output_path, "mp3", "64k"):
                    final_output = output_path
                    # Remove temp wav file
                    if os.path.exists(temp_wav_path) and temp_wav_path != output_path:
                        os.remove(temp_wav_path)
            elif audio_format == "M4B":
                # Pass chapters info for M4B format to add bookmarks
                print(f">> å¼€å§‹M4Bæ ¼å¼è½¬æ¢...")
                print(f"   è¾“å…¥æ–‡ä»¶: {wav_output}")
                print(f"   è¾“å‡ºæ–‡ä»¶: {output_path}")
                print(f"   ç« èŠ‚ä¿¡æ¯: {chapters}")
                
                conversion_success = convert_audio_format(wav_output, output_path, "m4b", "64k", chapters)
                if conversion_success:
                    final_output = output_path
                    print(f"âœ… M4Bè½¬æ¢æˆåŠŸ: {output_path}")
                    # Remove temp wav file
                    if os.path.exists(temp_wav_path) and temp_wav_path != output_path:
                        os.remove(temp_wav_path)
                        print(f">> å·²åˆ é™¤ä¸´æ—¶WAVæ–‡ä»¶: {temp_wav_path}")
                else:
                    print(f"âŒ M4Bè½¬æ¢å¤±è´¥ï¼Œä¿ç•™åŸWAVæ–‡ä»¶: {wav_output}")
                    # Keep the original WAV file if conversion fails
        
        print(f"æœ€ç»ˆè¾“å‡ºæ–‡ä»¶: {final_output}")
        print(f"=== éŸ³é¢‘ç”Ÿæˆå®Œæˆ ===")
        
        # æœ€ç»ˆæˆåŠŸçŠ¶æ€
        success_info = f"âœ… ç”ŸæˆæˆåŠŸï¼\nâ±ï¸ æ€»è€—æ—¶: {generation_time:.2f} ç§’\nğŸ“ æ–‡ä»¶: {os.path.basename(final_output)}\nğŸ“ å¤§å°: {os.path.getsize(final_output) / 1024 / 1024:.2f} MB"
        final_system_info = get_system_status()
        status_updates = update_status("âœ… ç”Ÿæˆå®Œæˆ", success_info, final_system_info, show_progress=True, show_system=True)
        
        # Clean up temporary prompt file if it was created
        if prompt_path and tempfile.gettempdir() in prompt_path:
            try:
                os.remove(prompt_path)
                print(f"å·²æ¸…ç†ä¸´æ—¶å‚è€ƒéŸ³é¢‘æ–‡ä»¶: {prompt_path}")
            except:
                pass  # Ignore cleanup errors
        
        return gr.update(value=final_output, visible=True), *status_updates
    
    except Exception as e:
        error_msg = f"âŒ ç”ŸæˆéŸ³é¢‘æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        print(f"ERROR: {error_msg}")
        import traceback
        error_traceback = traceback.format_exc()
        print(error_traceback)
        
        # é”™è¯¯çŠ¶æ€æ›´æ–°
        detailed_error = f"é”™è¯¯ç±»å‹: {type(e).__name__}\né”™è¯¯ä¿¡æ¯: {str(e)}\n\nè¯¦ç»†å †æ ˆ:\n{error_traceback}"
        status_updates = update_status("âŒ ç”Ÿæˆå¤±è´¥", "", "", detailed_error, show_error=True)
        
        # Clean up temporary prompt file if it was created
        try:
            if 'prompt_path' in locals() and prompt_path and tempfile.gettempdir() in prompt_path:
                os.remove(prompt_path)
                print(f"å·²æ¸…ç†ä¸´æ—¶å‚è€ƒéŸ³é¢‘æ–‡ä»¶: {prompt_path}")
        except:
            pass  # Ignore cleanup errors
            
        return gr.update(value=None, visible=True), *status_updates

def get_system_status():
    """è·å–ç³»ç»ŸçŠ¶æ€ä¿¡æ¯"""
    try:
        import psutil
        import os
        
        # GPUä¿¡æ¯
        gpu_info = ""
        if hasattr(tts, 'device') and 'cuda' in str(tts.device):
            try:
                import torch
                # å¼ºåˆ¶åŒæ­¥ç¡®ä¿è·å–æœ€æ–°æ˜¾å­˜ä¿¡æ¯
                torch.cuda.synchronize(tts.device)
                
                gpu_allocated = torch.cuda.memory_allocated(tts.device) / 1024**3
                gpu_reserved = torch.cuda.memory_reserved(tts.device) / 1024**3
                gpu_total = torch.cuda.get_device_properties(tts.device).total_memory / 1024**3
                gpu_usage = (gpu_allocated / gpu_total) * 100
                gpu_name = torch.cuda.get_device_name(tts.device)
                
                gpu_info = f"""ğŸ® GPUä¿¡æ¯:
{gpu_name}
å·²åˆ†é…: {gpu_allocated:.2f}GB
å·²ç¼“å­˜: {gpu_reserved:.2f}GB
æ€»å®¹é‡: {gpu_total:.2f}GB
ä½¿ç”¨ç‡: {gpu_usage:.1f}%"""
            except Exception as e:
                gpu_info = f"ğŸ® GPUä¿¡æ¯è·å–å¤±è´¥: {str(e)}"
        else:
            gpu_info = "ğŸ® å½“å‰ä½¿ç”¨CPUæ¨¡å¼"
        
        # ç³»ç»Ÿå†…å­˜ä¿¡æ¯
        memory = psutil.virtual_memory()
        cpu_percent = psutil.cpu_percent(interval=0.05)  # æ›´çŸ­çš„interval
        process_memory = psutil.Process(os.getpid()).memory_info().rss / 1024**3
        
        system_info = f"""ğŸ’¾ ç³»ç»Ÿå†…å­˜:
ä½¿ç”¨: {memory.used/1024**3:.2f}GB
æ€»è®¡: {memory.total/1024**3:.2f}GB
ä½¿ç”¨ç‡: {memory.percent:.1f}%

ğŸ–¥ï¸ CPUä½¿ç”¨ç‡: {cpu_percent:.1f}%

ğŸ“Š è¿›ç¨‹å†…å­˜: {process_memory:.2f}GB"""
        
        return f"{gpu_info}\n\n{system_info}"
        
    except Exception as e:
        return f"âŒ ç³»ç»Ÿä¿¡æ¯è·å–å¤±è´¥: {str(e)}"

def clear_gpu_cache():
    """Clear GPU cache and return memory info"""
    try:
        if hasattr(tts, 'comprehensive_memory_cleanup'):
            # ä½¿ç”¨æ–°çš„å…¨é¢å†…å­˜æ¸…ç†æ–¹æ³•
            if hasattr(tts, 'device') and 'cuda' in str(tts.device):
                import torch
                memory_before = torch.cuda.memory_allocated(tts.device) / 1024**3  # GB
                tts.comprehensive_memory_cleanup(verbose=True)
                memory_after = torch.cuda.memory_allocated(tts.device) / 1024**3  # GB
                
                message = f"GPUå†…å­˜å…¨é¢æ¸…ç†å®Œæˆ\næ¸…ç†å‰: {memory_before:.2f}GB\næ¸…ç†å: {memory_after:.2f}GB\né‡Šæ”¾: {memory_before - memory_after:.2f}GB"
            else:
                tts.comprehensive_memory_cleanup(verbose=True)
                message = "å†…å­˜æ¸…ç†å®Œæˆï¼ˆéCUDAè®¾å¤‡ï¼‰"
        elif hasattr(tts, 'torch_empty_cache'):
            # å›é€€åˆ°æ™®é€šæ¸…ç†æ–¹æ³•
            memory_before = 0
            memory_after = 0
            
            if hasattr(tts, 'device') and 'cuda' in str(tts.device):
                import torch
                memory_before = torch.cuda.memory_allocated(tts.device) / 1024**3  # GB
                tts.torch_empty_cache(verbose=True)
                memory_after = torch.cuda.memory_allocated(tts.device) / 1024**3  # GB
                
                message = f"GPUç¼“å­˜å·²æ¸…ç†\næ¸…ç†å‰: {memory_before:.2f}GB\næ¸…ç†å: {memory_after:.2f}GB\né‡Šæ”¾: {memory_before - memory_after:.2f}GB"
            else:
                tts.torch_empty_cache()
                message = "ç¼“å­˜å·²æ¸…ç†ï¼ˆéCUDAè®¾å¤‡ï¼‰"
        else:
            message = "TTSæ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•æ¸…ç†ç¼“å­˜"
            
        print(f">> {message}")
        return message
        
    except Exception as e:
        error_message = f"æ¸…ç†ç¼“å­˜æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        print(f">> {error_message}")
        return error_message

def update_prompt_audio():
    update_button = gr.update(interactive=True)
    return update_button

def process_uploaded_file(file):
    """Process uploaded text/epub file"""
    if file is None:
        return "", "", "", ""
    
    file_path = file.name
    filename = os.path.basename(file_path)
    file_ext = os.path.splitext(filename)[1].lower()
    
    chapters = []  # Initialize chapters list
    
    if file_ext == '.txt':
        content = read_txt_file(file_path)
    elif file_ext == '.epub':
        content, chapters = read_epub_file(file_path)
    else:
        return "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œä»…æ”¯æŒ .txt å’Œ .epub æ–‡ä»¶", "", "", ""
    
    # Limit preview length to prevent browser crashes with large files
    max_preview_chars = 10000  # çº¦10,000å­—ç¬¦é¢„è§ˆ
    if len(content) > max_preview_chars:
        preview_content = content[:max_preview_chars] + f"\n\n... (æ–‡ä»¶è¿‡é•¿ï¼Œä»…æ˜¾ç¤ºå‰{max_preview_chars}å­—ç¬¦ä½œä¸ºé¢„è§ˆã€‚å®Œæ•´å†…å®¹å°†ç”¨äºéŸ³é¢‘ç”Ÿæˆã€‚)"
        if chapters:
            preview_content += f"\n\næ£€æµ‹åˆ° {len(chapters)} ä¸ªç« èŠ‚ï¼Œç”ŸæˆM4Bæ ¼å¼æ—¶å°†æ·»åŠ ç« èŠ‚ä¹¦ç­¾ã€‚"
        return preview_content, filename, content, chapters  # Return preview, filename, full content, and chapters
    
    if chapters:
        content += f"\n\næ£€æµ‹åˆ° {len(chapters)} ä¸ªç« èŠ‚ï¼Œç”ŸæˆM4Bæ ¼å¼æ—¶å°†æ·»åŠ ç« èŠ‚ä¹¦ç­¾ã€‚"
    
    return content, filename, content, chapters  # Return same content for both preview and full, plus chapters

def refresh_sample_files():
    """Refresh the list of sample files"""
    files = get_sample_files()
    if not files:
        return gr.update(choices=["æ— å¯ç”¨æ–‡ä»¶"], value="æ— å¯ç”¨æ–‡ä»¶"), gr.update(value=None)
    
    # Update dropdown and preview audio
    default_audio_path = os.path.join("samples", files[0])
    if not os.path.exists(default_audio_path):
        default_audio_path = None
    
    return (
        gr.update(choices=files, value=files[0]),
        gr.update(value=default_audio_path)
    )

def on_sample_audio_change(selected_file):
    """Handle sample audio selection change"""
    if selected_file and selected_file != "æ— å¯ç”¨æ–‡ä»¶":
        file_path = os.path.join("samples", selected_file)
        if os.path.exists(file_path):
            # Since we only include standard audio formats, we can always preview
            return gr.update(value=file_path, label="å‚è€ƒéŸ³é¢‘é¢„è§ˆ", visible=True)
    return gr.update(value=None, label="å‚è€ƒéŸ³é¢‘é¢„è§ˆ", visible=True)

with gr.Blocks(title="IndexTTS Demo") as demo:
    mutex = threading.Lock()
    gr.HTML('''
    <h2><center>IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System</h2>
    <h2><center>(ä¸€æ¬¾å·¥ä¸šçº§å¯æ§ä¸”é«˜æ•ˆçš„é›¶æ ·æœ¬æ–‡æœ¬è½¬è¯­éŸ³ç³»ç»Ÿ)</h2>
<p align="center">
<a href='https://arxiv.org/abs/2502.05512'><img src='https://img.shields.io/badge/ArXiv-2502.05512-red'></a>
</p>
    ''')
    with gr.Tab("éŸ³é¢‘ç”Ÿæˆ"):
        with gr.Row():
            with gr.Column(scale=1):
                # å‚è€ƒéŸ³é¢‘é€‰æ‹©
                gr.Markdown("**å‚è€ƒéŸ³é¢‘é€‰æ‹©**")
                with gr.Row():
                    sample_files = get_sample_files()
                    default_choices = sample_files if sample_files else ["æ— å¯ç”¨æ–‡ä»¶"]
                    default_value = sample_files[0] if sample_files else "æ— å¯ç”¨æ–‡ä»¶"
                    
                    sample_dropdown = gr.Dropdown(
                        label="é€‰æ‹©æ ·æœ¬éŸ³é¢‘",
                        choices=default_choices,
                        value=default_value,
                        interactive=True
                    )
                    refresh_btn = gr.Button("åˆ·æ–°", size="sm")
                
                # è®¾ç½®é»˜è®¤é¢„è§ˆéŸ³é¢‘
                default_audio_path = None
                if sample_files:
                    default_audio_path = os.path.join("samples", sample_files[0])
                    if not os.path.exists(default_audio_path):
                        default_audio_path = None
                
                prompt_audio = gr.Audio(
                    label="å‚è€ƒéŸ³é¢‘é¢„è§ˆ",
                    key="prompt_audio", 
                    interactive=False,
                    value=default_audio_path
                )
                
                # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
                gr.Markdown("**æ–‡æœ¬è¾“å…¥**")
                uploaded_file = gr.File(
                    label="ä¸Šä¼ æ–‡æœ¬æ–‡ä»¶ (æ”¯æŒ .txt å’Œ .epub)",
                    file_types=[".txt", ".epub"],
                    key="uploaded_file"
                )
                uploaded_filename = gr.State("")
                full_text_content = gr.State("")
                chapters_info = gr.State([])
                
            with gr.Column(scale=2):
                input_text_single = gr.TextArea(
                    label="æ–‡æœ¬å†…å®¹",
                    key="input_text_single", 
                    placeholder="è¯·è¾“å…¥ç›®æ ‡æ–‡æœ¬æˆ–ä¸Šä¼ æ–‡ä»¶", 
                    info="å½“å‰æ¨¡å‹ç‰ˆæœ¬{}".format(tts.model_version or "1.0"),
                    lines=10
                )
                
                with gr.Row():
                    with gr.Column(scale=1):
                        infer_mode = gr.Radio(
                            choices=["æ™®é€šæ¨ç†", "æ‰¹æ¬¡æ¨ç†"], 
                            label="æ¨ç†æ¨¡å¼",
                            info="æ‰¹æ¬¡æ¨ç†ï¼šæ›´é€‚åˆé•¿å¥ï¼Œæ€§èƒ½ç¿»å€",
                            value="æ™®é€šæ¨ç†"
                        )
                    
                    # ä¿å­˜è®¾ç½®
                    with gr.Column(scale=1):
                        auto_save = gr.Checkbox(label="è‡ªåŠ¨ä¿å­˜", value=True, info="ç”Ÿæˆå®Œæˆåè‡ªåŠ¨ä¿å­˜åˆ°outputsæ–‡ä»¶å¤¹")
                        background_mode = gr.Checkbox(
                            label="æ™ºèƒ½åå°å¤„ç†", 
                            value=True, 
                            info="é•¿æ–‡æœ¬è‡ªåŠ¨åå°å¤„ç†ï¼Œé¿å…è¿æ¥è¶…æ—¶"
                        )
                        audio_format = gr.Radio(
                            choices=["WAV", "MP3", "M4B"], 
                            label="éŸ³é¢‘æ ¼å¼",
                            value="MP3",
                            info="MP3: 64kbpså‹ç¼©æ ¼å¼\nM4B: æœ‰å£°ä¹¦æ ¼å¼"
                        )
                
                gen_button = gr.Button("ç”Ÿæˆè¯­éŸ³", key="gen_button", interactive=True, variant="primary", size="lg")
                
                # å†…å­˜ç®¡ç†åŒºåŸŸ
                with gr.Row():
                    clear_cache_btn = gr.Button("æ¸…ç†GPUç¼“å­˜", variant="secondary", size="sm")
                    cache_info = gr.Textbox(label="ç¼“å­˜ä¿¡æ¯", interactive=False, max_lines=4, visible=False)
                
                # ç”ŸæˆçŠ¶æ€æ˜¾ç¤ºåŒºåŸŸ
                with gr.Accordion("ç”ŸæˆçŠ¶æ€å’Œç³»ç»Ÿç›‘æ§", open=True):
                    with gr.Row():
                        with gr.Column(scale=2):
                            status_info = gr.Textbox(
                                label="å½“å‰çŠ¶æ€", 
                                value="ç­‰å¾…å¼€å§‹ç”Ÿæˆ...",
                                interactive=False,
                                max_lines=3
                            )
                            progress_info = gr.Textbox(
                                label="è¯¦ç»†è¿›åº¦",
                                placeholder="è¿›åº¦ä¿¡æ¯å°†åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­æ˜¾ç¤º...",
                                interactive=False,
                                max_lines=8,
                                visible=False
                            )
                        with gr.Column(scale=1):
                            system_info = gr.Textbox(
                                label="ç³»ç»Ÿä¿¡æ¯",
                                placeholder="ç³»ç»Ÿç›‘æ§ä¿¡æ¯å°†åœ¨ç”Ÿæˆæ—¶æ˜¾ç¤º...",
                                interactive=False,
                                max_lines=8,
                                visible=False
                            )
                    
                    error_info = gr.Textbox(
                        label="é”™è¯¯ä¿¡æ¯",
                        interactive=False,
                        max_lines=4,
                        visible=False
                    )
                    
        output_audio = gr.Audio(label="ç”Ÿæˆç»“æœ", visible=True, key="output_audio")
        with gr.Accordion("é«˜çº§ç”Ÿæˆå‚æ•°è®¾ç½®", open=False):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("**GPT2 é‡‡æ ·è®¾ç½®** _å‚æ•°ä¼šå½±å“éŸ³é¢‘å¤šæ ·æ€§å’Œç”Ÿæˆé€Ÿåº¦è¯¦è§[Generation strategies](https://huggingface.co/docs/transformers/main/en/generation_strategies)_")
                    with gr.Row():
                        do_sample = gr.Checkbox(label="do_sample", value=True, info="æ˜¯å¦è¿›è¡Œé‡‡æ ·")
                        temperature = gr.Slider(label="temperature", minimum=0.1, maximum=2.0, value=1.0, step=0.1)
                    with gr.Row():
                        top_p = gr.Slider(label="top_p", minimum=0.0, maximum=1.0, value=0.8, step=0.01)
                        top_k = gr.Slider(label="top_k", minimum=0, maximum=100, value=30, step=1)
                        num_beams = gr.Slider(label="num_beams", value=3, minimum=1, maximum=10, step=1)
                    with gr.Row():
                        repetition_penalty = gr.Number(label="repetition_penalty", precision=None, value=10.0, minimum=0.1, maximum=20.0, step=0.1)
                        length_penalty = gr.Number(label="length_penalty", precision=None, value=0.0, minimum=-2.0, maximum=2.0, step=0.1)
                    max_mel_tokens = gr.Slider(label="max_mel_tokens", value=600, minimum=50, maximum=tts.cfg.gpt.max_mel_tokens, step=10, info="ç”ŸæˆTokenæœ€å¤§æ•°é‡ï¼Œè¿‡å°å¯¼è‡´éŸ³é¢‘è¢«æˆªæ–­", key="max_mel_tokens")
                    # with gr.Row():
                    #     typical_sampling = gr.Checkbox(label="typical_sampling", value=False, info="ä¸å»ºè®®ä½¿ç”¨")
                    #     typical_mass = gr.Slider(label="typical_mass", value=0.9, minimum=0.0, maximum=1.0, step=0.1)
                with gr.Column(scale=2):
                    gr.Markdown("**åˆ†å¥è®¾ç½®** _å‚æ•°ä¼šå½±å“éŸ³é¢‘è´¨é‡å’Œç”Ÿæˆé€Ÿåº¦_")
                    with gr.Row():
                        max_text_tokens_per_sentence = gr.Slider(
                            label="åˆ†å¥æœ€å¤§Tokenæ•°", value=120, minimum=20, maximum=tts.cfg.gpt.max_text_tokens, step=2, key="max_text_tokens_per_sentence",
                            info="å»ºè®®80~200ä¹‹é—´ï¼Œå€¼è¶Šå¤§ï¼Œåˆ†å¥è¶Šé•¿ï¼›å€¼è¶Šå°ï¼Œåˆ†å¥è¶Šç¢ï¼›è¿‡å°è¿‡å¤§éƒ½å¯èƒ½å¯¼è‡´éŸ³é¢‘è´¨é‡ä¸é«˜",
                        )
                        sentences_bucket_max_size = gr.Slider(
                            label="åˆ†å¥åˆ†æ¡¶çš„æœ€å¤§å®¹é‡ï¼ˆæ‰¹æ¬¡æ¨ç†ç”Ÿæ•ˆï¼‰", value=8, minimum=1, maximum=16, step=1, key="sentences_bucket_max_size",
                            info="å»ºè®®4-10ä¹‹é—´ï¼Œå€¼è¶Šå¤§ï¼Œä¸€æ‰¹æ¬¡æ¨ç†åŒ…å«çš„åˆ†å¥æ•°è¶Šå¤šï¼Œè¿‡å¤§å¯èƒ½å¯¼è‡´å†…å­˜æº¢å‡º",
                        )
                    with gr.Accordion("é¢„è§ˆåˆ†å¥ç»“æœ", open=True) as sentences_settings:
                        sentences_preview = gr.Dataframe(
                            headers=["åºå·", "åˆ†å¥å†…å®¹", "Tokenæ•°"],
                            key="sentences_preview",
                            wrap=True,
                        )
            advanced_params = [
                do_sample, top_p, top_k, temperature,
                length_penalty, num_beams, repetition_penalty, max_mel_tokens,
                # typical_sampling, typical_mass,
            ]
        
        if len(example_cases) > 0:
            gr.Examples(
                examples=example_cases,
                inputs=[prompt_audio, input_text_single, infer_mode],
            )
    
    # ä»»åŠ¡ç®¡ç†é¡µé¢
    with gr.Tab("ä»»åŠ¡ç®¡ç†"):
        gr.Markdown("## åå°ä»»åŠ¡ç®¡ç†")
        gr.Markdown("æ­¤é¡µé¢æ˜¾ç¤ºæ‰€æœ‰åå°éŸ³é¢‘ç”Ÿæˆä»»åŠ¡çš„çŠ¶æ€ã€‚é•¿æ–‡æœ¬ä¼šè‡ªåŠ¨æäº¤åˆ°åå°å¤„ç†ï¼Œæ‚¨å¯ä»¥å…³é—­æµè§ˆå™¨ï¼Œä»»åŠ¡å°†ç»§ç»­è¿è¡Œã€‚")
        
        with gr.Row():
            refresh_tasks_btn = gr.Button("åˆ·æ–°ä»»åŠ¡çŠ¶æ€", variant="primary", size="sm")
            clear_tasks_btn = gr.Button("æ¸…ç†å·²å®Œæˆä»»åŠ¡", variant="secondary", size="sm")
        
        # ä»»åŠ¡åˆ—è¡¨æ˜¾ç¤º
        tasks_display = gr.Dataframe(
            headers=["ä»»åŠ¡ID", "çŠ¶æ€", "è¿›åº¦ä¿¡æ¯", "ç»“æœæ–‡ä»¶", "é”™è¯¯ä¿¡æ¯"],
            label="ä»»åŠ¡åˆ—è¡¨",
            interactive=False,
            wrap=True
        )
        
        # ä»»åŠ¡è¯¦æƒ…æ˜¾ç¤º
        with gr.Accordion("ä»»åŠ¡è¯¦æƒ…", open=False):
            task_id_input = gr.Textbox(label="ä»»åŠ¡ID", placeholder="è¾“å…¥ä»»åŠ¡IDæŸ¥çœ‹è¯¦æƒ…")
            task_detail_btn = gr.Button("æŸ¥çœ‹è¯¦æƒ…", size="sm")
            
            task_detail_status = gr.Textbox(label="ä»»åŠ¡çŠ¶æ€", interactive=False)
            task_detail_progress = gr.Textbox(label="è¿›åº¦è¯¦æƒ…", interactive=False, lines=5)
            task_detail_result = gr.Textbox(label="ç»“æœæ–‡ä»¶", interactive=False)
            task_detail_error = gr.Textbox(label="é”™è¯¯ä¿¡æ¯", interactive=False, lines=5, visible=False)
            
            # ä¸‹è½½ç»“æœæ–‡ä»¶æŒ‰é’®
            download_result_btn = gr.Button("ä¸‹è½½ç»“æœæ–‡ä»¶", variant="primary", size="sm", visible=False)
            result_file_download = gr.File(label="ä¸‹è½½æ–‡ä»¶", visible=False)
        
        # ä»»åŠ¡ç®¡ç†å‡½æ•°
        def refresh_tasks():
            """åˆ·æ–°ä»»åŠ¡åˆ—è¡¨"""
            tasks = get_all_tasks()
            data = []
            for task_id, task_info in tasks.items():
                status = task_info.get("status", "æœªçŸ¥")
                progress = task_info.get("progress", "")[:100] + "..." if len(task_info.get("progress", "")) > 100 else task_info.get("progress", "")
                result = os.path.basename(task_info.get("result", "")) if task_info.get("result") else ""
                error = task_info.get("error", "")[:50] + "..." if len(task_info.get("error", "")) > 50 else task_info.get("error", "")
                data.append([task_id, status, progress, result, error])
            
            return gr.update(value=data)
        
        def clear_tasks():
            """æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡"""
            cleared_count = clear_completed_tasks()
            # åˆ·æ–°ä»»åŠ¡åˆ—è¡¨
            tasks = get_all_tasks()
            data = []
            for task_id, task_info in tasks.items():
                status = task_info.get("status", "æœªçŸ¥")
                progress = task_info.get("progress", "")[:100] + "..." if len(task_info.get("progress", "")) > 100 else task_info.get("progress", "")
                result = os.path.basename(task_info.get("result", "")) if task_info.get("result") else ""
                error = task_info.get("error", "")[:50] + "..." if len(task_info.get("error", "")) > 50 else task_info.get("error", "")
                data.append([task_id, status, progress, result, error])
            
            return gr.update(value=data)
        
        def show_task_detail(task_id):
            """æ˜¾ç¤ºä»»åŠ¡è¯¦æƒ…"""
            if not task_id:
                return "", "", "", "", gr.update(visible=False), gr.update(visible=False)
            
            task_info = get_task_status(task_id)
            status = task_info.get("status", "ä»»åŠ¡ä¸å­˜åœ¨")
            progress = task_info.get("progress", "")
            result = task_info.get("result", "")
            error = task_info.get("error", "")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æœæ–‡ä»¶å¯ä¸‹è½½
            show_download = bool(result and os.path.exists(result))
            show_error = bool(error)
            
            return (
                status,
                progress,
                result,
                error,
                gr.update(visible=show_download),
                gr.update(visible=show_error)
            )
        
        def prepare_download(task_id):
            """å‡†å¤‡ä¸‹è½½ç»“æœæ–‡ä»¶"""
            task_info = get_task_status(task_id)
            result_file = task_info.get("result", "")
            
            if result_file and os.path.exists(result_file):
                return gr.update(value=result_file, visible=True)
            else:
                return gr.update(value=None, visible=False)
        
        # ç»‘å®šäº‹ä»¶
        refresh_tasks_btn.click(refresh_tasks, outputs=[tasks_display])
        clear_tasks_btn.click(clear_tasks, outputs=[tasks_display])
        
        task_detail_btn.click(
            show_task_detail,
            inputs=[task_id_input],
            outputs=[task_detail_status, task_detail_progress, task_detail_result, task_detail_error, download_result_btn, task_detail_error]
        )
        
        download_result_btn.click(
            prepare_download,
            inputs=[task_id_input],
            outputs=[result_file_download]
        )
        
        # è‡ªåŠ¨åˆ·æ–°ä»»åŠ¡çŠ¶æ€ï¼ˆå¯é€‰ï¼‰
        # æ³¨æ„ï¼šè¿™ä¼šå¢åŠ æœåŠ¡å™¨è´Ÿè½½ï¼Œå»ºè®®æ‰‹åŠ¨åˆ·æ–°
        # demo.load(refresh_tasks, outputs=[tasks_display], every=5)

    def on_input_text_change(text, max_tokens_per_sentence):
        if text and len(text) > 0:
            text_tokens_list = tts.tokenizer.tokenize(text)

            sentences = tts.tokenizer.split_sentences(text_tokens_list, max_tokens_per_sentence=int(max_tokens_per_sentence))
            data = []
            for i, s in enumerate(sentences):
                sentence_str = ''.join(s)
                tokens_count = len(s)
                data.append([i, sentence_str, tokens_count])
            
            return {
                sentences_preview: gr.update(value=data, visible=True, type="array"),
            }
        else:
            df = pd.DataFrame([], columns=["åºå·", "åˆ†å¥å†…å®¹", "Tokenæ•°"])
            return {
                sentences_preview: gr.update(value=df)
            }

    # Event handlers
    input_text_single.change(
        on_input_text_change,
        inputs=[input_text_single, max_text_tokens_per_sentence],
        outputs=[sentences_preview]
    )
    max_text_tokens_per_sentence.change(
        on_input_text_change,
        inputs=[input_text_single, max_text_tokens_per_sentence],
        outputs=[sentences_preview]
    )
    
    # Handle sample audio selection
    sample_dropdown.change(
        on_sample_audio_change,
        inputs=[sample_dropdown],
        outputs=[prompt_audio]
    )
    
    # Handle refresh button
    refresh_btn.click(
        refresh_sample_files,
        outputs=[sample_dropdown, prompt_audio]
    )
    
    # Handle file upload
    uploaded_file.upload(
        process_uploaded_file,
        inputs=[uploaded_file],
        outputs=[input_text_single, uploaded_filename, full_text_content, chapters_info]
    )

    # Handle generation with new parameters
    gen_button.click(
        gen_single,
        inputs=[
            prompt_audio, input_text_single, infer_mode,
            max_text_tokens_per_sentence, sentences_bucket_max_size,
            auto_save, audio_format, uploaded_filename, sample_dropdown, full_text_content, chapters_info, background_mode,
            *advanced_params,
        ],
        outputs=[output_audio, status_info, progress_info, system_info, error_info]
    )
    
    # Handle cache clearing
    def handle_cache_clear():
        message = clear_gpu_cache()
        return gr.update(value=message, visible=True)
    
    clear_cache_btn.click(
        handle_cache_clear,
        outputs=[cache_info]
    )


if __name__ == "__main__":
    try:
        demo.queue(20)
        demo.launch(
            server_name=cmd_args.host, 
            server_port=cmd_args.port, 
            inbrowser=True,
            share=False,  # ä¸ä½¿ç”¨å…¬å…±é“¾æ¥
            debug=False,  # å…³é—­è°ƒè¯•æ¨¡å¼
            quiet=True,   # å‡å°‘æ—¥å¿—è¾“å‡º
            show_error=True,  # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            allowed_paths=["outputs", "samples", "tests"]  # å…è®¸è®¿é—®çš„è·¯å¾„
        )
    except KeyboardInterrupt:
        print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨å®‰å…¨é€€å‡º...")
    except Exception as e:
        print(f"å¯åŠ¨WebUIæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
